The formalism for 42 is divided in files, 
The first file, FullGrammar(274), contains all abstract grammars,
the concrete grammar for the full language and the well formedness criteria.

It is important to familiarize with the CORE grammar,
while the other grammatical forms can be understood when needed while reading
the rest of the formalism.
The most important difference between CORE, FULL and CMP grammars
is how they handle nested classes and library literals, as explained below:

CORE is a minimal grammar, a CORE.L is a library literal with
cached informations about typing and dependencies.
Library literals contained in CORE expressions are of form CORE.L
Nested classes inside a CORE.L are directly defined by a CORE.L

CMP is a richer grammar, but there is not a library literal of form CMP.L.
Library literals contained in CMP expressions are of form CORE.L

FULL is very similar to CMP, but allows for library literals of form FULL.L
Method bodies in a FULL.L are expressions of CMP.
Nested classes inside a FULL.L are defined using a FULL expression;
Library literals contained in FULL expressions are of form FULL.L or CORE.L

The file Common(111) contains the definition for operations over the program p, subtyping
and few other notations that every other part of this formalism could use.

Finally, the file Top(122) define the top level reduction p==>p',
proceeding left to right, top to bottom to transform FULL expressions into
core one, and executing code as needed.
Top depends on 3 other components:
  normalization (defined in file norm 133+152+128), transform a CMP.e into a CORE.e,
  and a FULL.L where all the nested classes are defined with CORE.L into
  a CORE.L.
  
  typing (defined in file Typing 178), checks if a CORE.e or a CORE.L are
  well typed with respect to a program
  
  expression execution (defined in file reductionAndNative 75), implementing
  small step reduction for CORE.e with respect to a program.
  
Of those components, the most complex is normalization; relying on components
toCore (in file toCore) and PAcc (in file ConstraintAccumulation).
Normalization is fundamental to understand the connection between the rich
FULL language and the minimal CORE language.
However, all correctness properties of 42 are stated on the CORE language
and are unrelated to the FULL language; thus they can be understood
without a deep understanding of normalization.
  

All notations:  now is 1173, realistically is going to sit at 1200/1250
____________________
1FullGrammar
  all grammars
  concrete grammar
  well formedness
  271 (will grow a little)
_____________________
Common for all parts: (file program:90+) TODO: rename filename
[from P]
p operations
function notations
inside
MH/MWT notations
cX/FV
p|-T0<=T1, p|-P0<=P1, p|-T<=Tz  //TODO: still to add
trustedClass(CORE.L)
methodName(OP) and other syntax mangling
noFwd //TODO: notation below still to add
from
toRead(T)
toRead(G)

----
__________________
top level notation (file top 141)
p ==> p'
  adapt(CORE.e,P)
  followUrls
  readFolder
  refreshUniqueNames(CORE.L)
  |- p -> LL
    typable(p)=Csz
    LL[Csz=Flag]=LL'
uses major
  coherentClasses(p,CORE.e)
  p|-CORE.e :CORE.T<=CORE.T' / |- p
  infer(p,e)
  norm(p,C.L)
  A|e --> A'|e'  
  
  
_______________
expression reduction (file reductionAndNative 75)
 A|e --> A'|e' 
   A operations:
     A.rog(v)
     A.free()
     A.pathOf(v)
     A[mdf v0..vn]=A'
     A[mdf x=v]=A'
     A~as = A'
   accessibleAddresses(A;Ts;vs)=as
   mutLibs(A;Ts;vs) = A'
__________________
check coherence: (file top --)
coherentClasses(p,CORE.e)
  coherent(p)
  coherentGetMdf(mdf0,mdf1,mdfs0,mdfs1)
    fieldTypes(MHs,x, mdf)
    fieldAccessMdf(MHs,x, mdf)
__________________
expression type system (file typing: 163)
D|-CORE.e :CORE.T<=CORE.T'  /  |-p
  D |- ds | G0 
  D |-k1..kn : T1..Tn <= T | Ts;Ps
  D |-k : T' <= T |Ts;Ps
  p |-M
  mostGeneralMdf(mdfs)=mdf
    generalEnough(mdfs)=mdfs'
  methTypes(p,P,s) = MethT
  fwd_or_fwd%_in
  fwd% T
  mutToCapsule
  toImmOrCapsule
  toLent(T)
  toLent(G)
  mutToCapsuleAndFwdMutToFwdImm
  mutToCapsuleAndFwdRead
  
__________________
normalization (file norm 73)
norm(p,C.L)
  collectDeps(CORE.L)
    collectDepsE(CORE.e)
  expandFields(Ms)
  collect(p,Ts)
  methods(p,P0)
  alive(p,P)
use major
  infer(p,Ms)


_________________________
inference (file inference 198)
infer(p,C.Ms)=CORE.Ms /infer(p,C.e)=CORE.e
  I(HALF.M)=CORE.M
    I(HALF.e) = CORE.e
      I(HALF.D) = CORE.D
      I(HALF.K) = CORE.K
      I[DS]
      iType(I,C.T)
  solve(p, CCz)
    commonSuperT(p,Tz)=Tz'
    chooseT(CCz;Tz)=T
      mostSpecific(Tz) = T
uses major
  Y♥C.e/p♥C.M
  PAcc operations
  
_________________________
PAcc operations (file inference --)
  .fixInfer(HALF.Ms) =CCz
  .collect()=PAcc'
  .add(C.Ms)=PAcc'
  .add(C.M)=PAcc'
  PAcc[CCz]=PAcc'
  PAcc[GX]
  PAcc[D1..Dn]
  PT,s,i = PAcc.selectedOption(OP, PTs, xPs)
    PT,s,i in PAcc.opOptions(OP, PTs, xPs)
      PAcc.paramaterPaths(PT, s) 
      PAcc.unsatisfiable()
        origin(p;s;P) 

_________________________
toCore (file toCore 152)
Y♥C.e=HALF.e / p♥C.M=HALF.M
  Y♥FULL.par = (x=HALF.e)s
  Y♥FULL.DE = HALF.D
  toBinOp(x,Op=)= 'a part of an expression'
  Y(xP)
  
Main concepts:

-most important grammatic forms:
FULL.e: the expressive syntax for expressions used by the programmer
CORE.e: the minimal syntax used as internal representation and convenient for metaprogramming.
FULL.L: library literal with expressive syntax.
CORE.L: library literal with minimal syntax.
LL: either a FULL.L or a CORE.L
p: a program; similar to a stack of LL to represent nested scopes.
P: a path
CORE.T/FULL.T: types
ctxC: forall ctxC, all LL top-left of the hole are of form CORE.L
  The compilation context, e=ctxC[LL] selects an LL where
  all of the former LLs are CORE.L
  The context does not enter into libraries

-most important operations:
p(P):
  extract a library from a program
p==>p'
  top level reduction
e-->p e'
  expression reduction. It can uses native code to call functionalities
  outside of L42. Some of those are 'trusted and internally implemented'.
  All other ones are properly sandboxed.
norm(p,LL)
  reduces some libraries in the top of the program to core. 
p|-e:T
  expression well typed.
|-p->LL
  type some libraries in the top of the program and annotate them as 'typed'
  or 'coherent'; that is, executable. 


PAcc, I, Y: record contexts for normalization

execution flow:
  'L42 name' works as follow:
    -reads a file called either name.L42 or name/This0.L42.
      The file is parsed according to grammar LL
    -syntactic well formedness is checked
    -rules p==>p' are applied until the result is a well typed CORE.L
      Such rules may require to 
        -read code from urls; such code must be typed CORE.L. It could be cached locally.
        -read code from files, this will be parsed and integrated in the execution.
        -p♥Full.L
        -p:e:T
        -|-p->LL
        
Program p discussion:
Program-specific grammar is needed to represent the position
in the project (top level Library) that we are reducing.
For example, if our 42 project is
{ A=... B=This0.A.second({ method Library m(){C=This2.A.first({})} }) }
we first need to reduce "A.first({})"
In order to explicitly denote the meaning of "Thisn", we split the project
into the 3 part program
p={C=This2.A.first({})};{ method Library m()[]};{ A=... B=This0.A.second([]) }
Note that the first component is an L, while the others have a hole, [],
so they are of form ctxL.
Note how the first component uses This2.A in order to skip two levels
and refer to A in the outer most layer of our project.

It is possible to see the program as a stack, with a top() and a pop() operation.
Given a program is always possible to reconstruct the project
by doing a series of pop operations.
Since the top of the stack is of a different kind with respect to the other elements,
pop replaces the [] with the stack top to forge an L
push, the opposite of pop, extracts a piece of the top to forge a new top.
To do so, it takes in input the split form of the old head.
Finally, notice how in this model updating the top  can not be emulated with pop() + push()

Methods and collect discussion
methods(p,P0)=MWTs //methods returns a set: the order of the methods is not relevant
//methods(), applied to a CORE.L will just return the MWTs;
//applied to a FULL.L, will return a merge of the methods retrieved directly from the L and methods types declared
//in its implemented interfaces. It chooses a type in case of different refines in interface diamond implementations
//In this model cases like
//    A=  interface {refine method A m()}
//    B= [A]{ method A m()}
//are ok wrt B but fail for A

Collect performs a depth first but we avoid duplicates by keeping the rightmost occurrence.
We check absence of circularity by diverging
an implementation could keep a list of visited P instead of diverging; mathematically it is the same

        
--------------------------------------------
3 Multiple method types   T0..Tn-> T';Ps in methTypes(p,P,s)
--------------------------------------------
The main idea giving flexibility to the 42 type system is that
methods have many types, where only the modifiers change.
It can be seen as a form of polymorphism of the method types.
We here express the methodTypes set with metarules,
but a finite/predictable sequence of applications is always sufficient,
as shown later
  
  
xs sequence, xz set,
[]sequence, {}set
sequence\i removes the element i from the sequence