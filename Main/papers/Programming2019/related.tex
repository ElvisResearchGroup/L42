
\saveSpace
\section{Related work}
\label{s:related}
\saveSpace

\noindent\textit{Type Modifiers:}
We rely on a combination of modifiers that is supported by at least 3 languages/lines of research:
\REVComm{42}{3}{Typesetting error}~\cite{ServettoZucca15,ServettoEtAl13a,JOT:issue_2011_01/article1,GianniniEtAl16},
Gordon~\cite{GordonEtAl12}
and Pony~\cite{clebsch2015deny,clebsch2017orca},
each of these works is accompanied by proofs of the properties of those modifiers.
In our work we just assume the required properties hold.
 Those approaches all support deep/strong interpretation, without back-doors.

Approaches like Javari~\cite{TschantzErnst05,Boyland06} and Rust~\cite{matsakis2014rust}
are unsuitable since they introduce back-doors, and we can not expect the programmer to use them properly.
Many approaches just try to preserve purity (as for example~\cite{pearce2011jpure}),
but here we also need aliasing control.
Approaches like ownership~\cite{ClarkeEtAl13,ZibinEtAl10,DietlEtAl07}
are not sufficient since they aim to enforce properties only for
annotated objects and/or owned objects.
However, static verification can rely on ownership as a building block~\cite{%
muller2002modular,%
barnett2011specification%
}.%On ownership verification
%Peter Mueller and Arnd Peotzsch Heffter,  eg Müller, P.: Modular Specification and Verification of Object-Oriented Programs, 2002.
%M. Barnett and M. Fähndrich and K. R. M. Leino and P. Müller and W. Schulte and H. Venter: Specification and Verification: The Spec# Experience. Communications of the ACM, 2011.



%\noindent\textit{Strong Exception Safety:}
%Exception safety seems at first glance a smaller issue with respect 
%to the other two, but is the final piece that lets the whole system work in a real world setting.
%Note that state of the art type systems to enforce exception safety
% do not restrict code that do not capture errors, and
%only the point of error capturing is constrained.


\noindent
\textit{Object Capabilities:}
Object capabilities~\cite{RobustComposition}, in conjunction with type modifiers seem to be able to
 enforce purity of sections of code in a \REVComm{friendly}{3}{Nontechnical term} and modular way.
Here we present this idea very informally.
The language Joe-E~\cite{finifter2008verifiable}
explores how to use object capabilities to ensure
pure behaviour for methods.
In order to express Joe-E as a subset of Java,
they leverage on a simplified model of immutability:
immutable classes are final classes where all the fields are final and refer to other immutable classes.
%Instances of immutable classes are immutable objects.
In Joe-E every method taking only instances of immutable classes as input, is pure.
Their model would not allow verification of purity for invariant methods of any mutable objects.
In our model we have a more fine grained representation of immutable/read:
our’s is \emph{reference based} instead of \emph{class based}.
This means that in our model, every method taking only \Q@read@ or \Q@imm@ references as input is pure,
both in the sense that no object visible outside of the method is mutated, but also
that no I/O is performed.



\noindent\textit{Class invariants:}
Class invariants are a fundamental part of the design by contract methodology. 
Many languages and tools support some form of invariant verification (e.g. Eiffel~\cite{Meyer:1992:EL:129093}, D~\cite{Alexandrescu:2010:DPL:1875434}, JML~\cite{Burdy2005}, Spec\#~\cite{Barnett:2004:SPS:2131546.2131549}).
There is a large body of research in the literature on class invariants:
JML offers a tool (jmlrac~\cite{Burdy2005}) that is intentionally unsound,
while InvTS~\cite{gorbovitski08efficient} lets you write Python conditions
 that are verified on a set of Python objects, but the programmer needs to be able
 to predict which objects are in need of being checked and to use a simpler domain
 specific language to target them. That is, the programmer may make a mistake
while using this domain specific language, and the invariant checking
will not be triggered.
Validation is clearly related to class invariants, and can be used to represent them.
To this aim, \validate will define when the invariant is expected to hold:
literature on class invariant accepts that sometime the object invariant may not hold,
and that is exacerbated because of re-entrancy and aliasing
\cite{leino2004object,drossopoulou2008unified}.
%Leino, K. R. M. and Müller, P.: Object Invariants in Dynamic Contexts (ECOOP), 2004.
%S. Drossopoulou and A. Francalanza and  P. Müller and A. J. Summers: A Unified Framework for Verification Techniques for Object Invariants ECOOP 2008. 
There are different options as to when to check invariants:
\begin{itemize}
\item  when the object is in a \textit{steady} state:
 the execution is not inside any of its methods~\cite{Gopinathan:2008:RMO:1483018.1483028};
\item
at the start and at the end of every public method
(though it is unclear how to deal with recursive methods)~\cite{Burdy2005};
\item
constantly maintained between calls to public methods~\cite{WikiInvariant}
%\url{https://en.wikipedia.org/wiki/Class_invariant}};
%\item
%constantly maintained when the object is \textit{closed};
%invariant can be manually opened and closed by using special operations; % Add cite here!
\end{itemize}
%DONE IN INTRO breaking class invariants = bug in class code
%braking validation= DEPEND.
To encode this range of invariant semantics
in our approach we can add a boolean \Q@isOpen@ field and add \Q@this.isOpen || ..@
in front of the validity condition.
Validation can be used to manually encode complex scenarios,
for example if a method called on an object needs to break the invariant of another object,
it can do so by manually setting the \Q@isOpen@ flag on the other object.


%On ownership verification
%Peter Mueller and Arnd Peotzsch Heffter,  eg Müller, P.: Modular Specification and Verification of Object-Oriented Programs, 2002.
%M. Barnett and M. Fähndrich and K. R. M. Leino and P. Müller and W. Schulte and H. Venter: Specification and Verification: The Spec# Experience. Communications of the ACM, 2011.


\newcommand\sepItems{\saveSpace\saveSpace\saveSpace\\*${}_{}$\\*${}_{}\,\bullet\,$}

\noindent\textit{Sound and Unsound monitors:}
By looking to a survey by Voigt et al.~\cite{Voigt2013} and the extensive MOP project~\cite{meredith2012overview},
it seems that most \REVComm{\REVComm{RV}{2}{used before it is defined}}{3}{Abbreviation without full term} works have a philosophy that is radically different from ours;
indeed RV systems and frameworks are often tools empowering the user
in implementing what kind of monitoring they see fit for their specific problem at hand.
This means that users are responsible for deciding, designing and encoding both the 
logic properties and the instrumentation criteria that will perform operations
in certain moments in time~\cite{meredith2012overview}.
In practice, this means that the logic, the instrumentation, and the implementation end up connected:
a specific instrumentation strategy is good only to test certain logic properties in certain applications.
No guarantee is given that the implemented instrumentation strategy is able to support
the required logic in the monitored application.

%
%In this work we define a language where a minimal, standardized,
%efficient and completely general purpose instrumentation strategy can soundly verify conditions
%expressible as a\\* \Q@read method imm Bool invariant()@, for any well-typed program; with open world assumption
%and possible Byzantine behaviour of any object in the system.
%
%By seeing class invariant as a part of the type of the object,
%the `RV tool' philosophy is akin to letting the programmer customize the behaviour of the
%type system: the programmer implementation may be unsound; while our philosophy is
%to give the user a way to represent complex and expressive types (in the form of arbitrary code in 
%the \Q@invariant()@ method), but 
%the type system implementation is fixed in stone by the language designer.

\noindent Many works attempt to move out of the `RV tool' philosophy to ensure RV Monitors work as expected. Here
we mention some such works:
\sepItems
In avionics, where memory allocation is disallowed, making reasoning about aliasing much simpler~\cite{laurent2015assuring}:
``\emph{Runtime Verification (RV) can act as the last line of defense to
protect the public safety, but only if the RV system itself is trusted.}''.
%\sepItems
%In domain specific languages~\cite{ferrari2002guardians}:
%``\emph{Proof techniques for establishing security properties}''.
\sepItems
On assertions over restrictive domain specific languages, to tame some of the C/C++
undefined behaviour~\cite{agten2015sound}:
``\emph{no verified assertion in the verified
module will ever fail at runtime, even if the module runs as part of
a vulnerable application that is subject to code injection attacks}''.
\sepItems
Works on class based OO languages, but focusing only on pre and post conditions~\cite{findler2001contract}:
``\emph{we  study  the  problem  of  contract  enforcement in
an object-oriented world from  a foundational perspective.   More
specifically, we study contracts as refinements of types}''.
\sepItems
Jose~\cite{feldman2006jose} seems keen on sound theoretical principles:
``\emph{There are two issues involved
in the implementation of such a tool: the correct enforcement of the theoretical principles, and the instrumentation
of the code. Most previous tools tackle both issues, but have
subtle failures in one or the other.}'',
but when it comes to class invariants just perform checks around public methods:
``\emph{Invariants are checked at the end of the lowest-level constructor,
 and at the beginning and end of every non-private non-static method}''.\\*
The same behaviour happens in `Code Contracts'~\cite{fahndrich2010embedded},
jContractor~\cite{abercrombie2002jcontractor}
and~\cite{tran2003design}:``\emph{Invariants may be checked both before and after
method  execution  for  calls  crossing  object  boundaries.
Assertion  failures  result  in  appropriate  exceptions.}''.\\*
In this way methods still have to assume any object may be broken; in such case calling any
public getter would trigger an error, but while the object is just passed around
(and for example stored in collections), the broken state will not be detected.
Gopinathan ~\cite{Gopinathan:2008:RMO:1483018.1483028}
explains the danger of these approaches very clearly:
``\emph{there are many instances where o's invariant is violated by the programmer inadvertently changing the state
of p when o is in a steady state. Typically, o and p
are objects exposed by the API, and the programmer (who is the user of the API), unaware of
the dependency between o and p, calls a method of p in such a way that
o's invariant is violated. The fact that the violation occurred is detected
much later, when a method of o is called again, and it is difficult to 
determine exactly where such violations occur.}''\\*
Critically, even~\cite{Gopinathan:2008:RMO:1483018.1483028} is still unsound since they do not address either
the risk of non-determinism in the invariant, 
or the presence of exceptions.
\sepItems
Works over C\# recognize the need
for purity/determinism when method calls are allowed in contracts~\cite{barnett200499}
``\emph{There are three main current approaches: a) forbid the use of functions in specifications, b) allow only provably pure functions, or c) allow programmers free use
of functions. The first approach is not scalable, the second overly restrictive and
the third unsound.}''\\*
They recognize that many tools unsoundly use option (c), such as AsmL~\cite{barnett2003runtime}.
They propose a concept of observational purity, that if completely fleshed out
could possibly be a great addition to our proposed type system.
We speculate that some 
primitive language support may be needed, for example implementing the Flyweight pattern 
as part of the language semantics.
\sepItems
In environments offering powerful enough aspect-oriented support,
it could be possible to detect any field update in the whole ROG of
any object, following the strategy of 
Gopinathan et al.~\cite{Gopinathan:2008:RMO:1483018.1483028}.
Their approach is very computationally intensive, but it could even allow rolling-back the very field update that caused 
the invariant/validation to fail, making the object coherent again.
However, we think this would be a \REVComm{\REVComm{terrible}{2}{It seems in poor taste to complain of ``terrible'' ideas, especially without attempting to demonstrate the improvements of the proposed approach.}}{3}{Nontechnical term. It is not a great idea to label previous work as ``terrible''} idea causing unexpected strange behaviour, where some but not all
field updates are reverted while capturing an exception.
%: for example
%assume that we are moving object between two boats:
%the overflowing object may be removed from the \Q@cargo@ of the second boat, but it would not
%be placed back in the first boat. It would look like the object has disappeared.
%The important point here is that the program would be in an unexpected state
%even if no object invariants are violated, and this would happen \textbf{because} of the 
%invariant checking/fixing behaviour, not because of code written by the programmer.
%We believe that the only viable option is to detect violations after the fact.



\noindent\textit{Performance}
\REVComm{We believe our sound approach can monitor programs
for a fraction of the cost of many other approaches.}{3}{\label{CONTRA2}unsubstantiated and contradictory to [footnote \ref{CONTRA1}]}
Many other works%
~\cite{feldman2006jose,fahndrich2010embedded,abercrombie2002jcontractor,tran2003design}
 check/run
the invariant code at the start and end of every public
method; depending on the approach, this may even include trivial getters.
In  our approach, we call the \validate method
one time at the end of each setter, capsule mutator method and constructor.
We do not inject it at the end of other methods, which are usually more numerous and invoked much more often.
Of course, \validate can still be called indirectly, for example by calling a setter.
We expect our approach to result in a dramatic reduction over the number of required checks,
except for cases when public methods just update many fields directly (without using setters).







\noindent\textit{Security and DMZ:}
Static verification lets us reason about a complete program
and verify its correctness.
Traditional static verification is like a mathematical proof: a program is valid if it is \textbf{all correct},
but a single error invalidates all the claims.
Thus, it is hard to perform verification on large programs, or when independently
maintained third party libraries are involved.
\REVComm{To solve this issue, static verification systems are starting to}{2}{[is this correct?] verification of reference monitors, gradual typing, and contracts have been explored for longer} consider a verified core
and a run-time verified boundary.
You can see our approach as an extremely modularized version of such system:
every class is its own demilitarized zone, and the rest of the code 
could have Byzantine behaviour.
\REVComm{Every class that compiles/type checks is soundly validated
independently of the code that uses this class or any other surrounding code.}{3}{Is this claim justified}
Our approach works both with an open world assumption and in a library setting.
Consider for example the work of \REVComm{Matthew~\cite{parkinson2007class}}{2}{[Change to] Parkinson}:
in his short paper he verified an \Q@Observer@ class invariant over
a \Q@Subject/Observer@ pattern.
However, the proof relies on the method \Q@Subject.register(Observer)@ respecting its contract.
Such assumption is unrealistic in a real system with dynamic class loading,
and this invariant could trivially be broken by a user defined \Q@EvilSubject@.


\noindent\textit{Dedicated specification language or underling language:}
Using a specification languages near to the logic and disjointed from a specific language's
semantics may seem attractive, however
a study~\cite{chalin2007logical} discovered that developers expect
the specification language to use the semantics of the underling language, including
short circuit semantics and arithmetic exceptions; thus for example
\Q@1/0 || 2>1@
should not hold, while 
\Q@2>1 || 1/0@ should hold thanks to short circuit semantics.
This study was influential enough to convince JML to change its interpretation of logical expressions
accordingly~\cite{chalin2008jml}.
We believe this is evidence that using a method in the underlying language to encode the validation is
a developers-friendly solution.









%\noindent\textit{Theorem provers and SAT solvers}
%Rather than providing a simple set of rules as to what a \Q@validate@ method can contain,
%and where to insert calls to it, we could instead rely on implementation-specific static analysis:
% in which a \Q@validate@ method is valid iff the compiler can prove that it is deterministic
% and that it’s generated \Q@validate()@ calls are sufficient to enforce validation.
%Though approaches like this are frequently used such as with unifying Java’s generic-wildcards [], Rust’s ‘borrow checker’, …; we believe that would not produce a good result for our purposes: 
%\begin{itemize}
%	\item it would mean that a programmer would have no way of telling whether their code would compile, in particular code compiling would depend on the specific compiler (version) used.
%	\item the runtime cost of validation would be completely unpridictibable; since it is deterministic there is nothing stopping the compiler from calling \Q@validate@ any number of times, and at any point in time.
%	\item When a validation error could be throw would likewise be unpredictable, though it should happen after an object is made invalid\footnote{technically our definition of validation technically allows the error to happen sooner, as long as it’s not too late; however pre-emptive errors like this would be extremely hard to debug}, it could happen any time before it’s use. Making matters worse, if multiple object’s would be invalidated before either is used, which one’s error would be thrown is unconstrained
%	\item This approach will not work well in the pressence of dynamic code loading, in particular it woud likley significantly slow down such loading or spurioslly fail depending on what other code has been loaded
%\end{itemize}



%Conclusions? future work?
%@StrongExceptionSafety is 
%a very strong property,
%and some languages may be unwilling to commit to always preserve it.
%In particular, depending on the details of a specific language
% releasing resources as in \Q@finally@ blocks may require
%some relaxation of @StrongExceptionSafety. Sound releasing of resources could be interesting
%future work.
