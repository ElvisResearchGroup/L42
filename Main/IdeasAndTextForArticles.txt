Trivializing metaprogramming or supporting metaprogramming?
Metaprogramming is hard.
In 42 we want to support 
the difficoult task of creating relayable
metaprogramming operations, that consider all the side case,
not supporting a subset of cases and prevent the others by design.

For example: Data/AddEquals
we wish to add equals to a class,
and to do it by calling equals on all the fields.
This design seams intuitive and "good" but there are a ton
of side cases that needs to be supported. Let see how 42 
supports those:

-Simple definitions. No recursive types, no subtyping, all good.
All fields must implement equals, otherwhise error.
This is the trivial case, the goal of 42 design is to support
thinking more than about just this case.
Super trivializing would be a system that just do the task and give error
later if not all the <:Equals are satisfied. 

-recursive data
A:AddEquals<><{B b}
B:AddEquals<><{A a}

-nestedclasses
A:AddEquals<><{
  B b
  B:AddEquals<><{A a}
  }
##or
A:AddEquals<><{
  B b
  B:{A a}
  }

Let see how the design of the introspection library will help us to not trivialize AddEquals
We will iterate on the field types
i=Refactor.introspect(lib:that)
Location.Types ts=i.fieldTypes()
with t in ts.vals() (//Type is an interface
  with rc=t.referredClass() (
    on Location.Class.Named /*handle trivial case: need <: Equals*/
    on Location.Class.AnonNested /*do we want to retro fit AddEquals?*/ 
    on Location.Class.AnonTop/*you require yourself to be <:Equals, should be ok, right?*/
    on Location.Class.Unprocessed/*optimistic behaviour? pessimistic one?*/
    ))
the purpose of 42 is not to make those decisions once and for all,
but to create a framework where those decisions can be made and documented.


meta level soundness

a class is not well typed if assume something false of 
another class.
for example trying to sum Bool.
A class is well typed if assume true facts
for all referred classes.
A class is well typed w.r.t. Ps if assume true facts
for all classes Ps.
an expression containing Libraries and class objects
*refers* to all the classes referred by the Libraries
plus all the class objects, transitivelly.

openPs(p,e)={P| e refers_p P, p(P) not LC}
falsePs(p,e)={P| e refers_p P, p(P)= LC, e assume false over LC}

meta safety: openPs and falsePs never grow
-- but, consider the two solutions:
All:Fix<><{
  Person:Data<><{
    Persons friends
    Persons:Data<><{}
    }
  Persons:Collections.vector(of:Person)
  }

Person:Data<><{
  List friends
  $Top:Data<><{}
  List:Collections.vector(of:$Top)
  }
---
All:Data[\"Person";\"Car"]<><{
  Person:{
    Car.List cars
    $Top:Data<><{}
    List:Collections.vector(of:$Top)
    }
  Car:{
    Person.List owners
    $Top:Data<><{}
    List:Collections.vector(of:$Top)
    }
  }

---
Collections always take a complete, non class-any parameter.
What if all class object are non-any and to give a 
possibly broken one you need {/*@P*/}:imm Library?
common sugar may make it {@P}

in that case, the definition of *refer* can be simpler
    
  //testing alternative 42
  rc=t.referredClass()
  when (clazz=rc.asNamed() doBla(clazz))//capturing/discarding exception void
  //or with lambdas
  res=$(rc, inf:..)$:rc.matcher(result:Library)<><{
   Info inf
   method (named)
   /*using this.inf() and Named:named get result*/
   method (anonTop)
   /*using this.inf() and AnonTop:anonTop get result*/
   /*etcetera*/
   }
   resL=$(list)$:list.sorter()<><{
     method >(a,b) a.foo()>b.foo()
     }
   resL=list.sort(($:\<><{..}$))
   //what if sintactic sugar
   // ($:\<><{(T x)s..}$((x:e)s)== lambda{(T x=e)s ..}
   resL=list.sort(lambda{method >(a,b) a.foo()>b.foo()})
   //compare with
   resL=list.sort(lambda(a,b)->a.foo()>b.foo() )
    )



----------------------
42 verbosity for good
this. is required
explicit types at method boundaries
types for number/strings
types for collections
"closures" requires explicit passing of environment



----------------------
42 expressive power
is not important to make a language where
is easy to write a correct program if you know exactly what you want
is important to have wrong programs easily failing well
so, when thinking of a feature
-how can be used to acheive my goal :-(
-how can be misused :-|
-how can be used to guard my code against bugs :-)

good 42 libraries/towels should make you think of what can
go wrong first and upfront, even before completly fleshing out
the desired behaviour

on freedom is slavery:
every language feature that you can use is a feature you need
to guard against, since others can use it too.

many languages have many different kinds of features
In 42 you sort of have 2 main attack mechanism:
interface implementation: a very sharp knife
metaprogramming: an atomic bomb

and many protection mechanisms:
Types and modifiers, exceptions, sandboxing (soon)



----------------------

(Integrated) Metaprogramming and 42

Integrated metaprogramming is when you can generate code
and compile it/run it without manually import 
the generated code in a new program, this include both
compile time and run time metaprogramming, but excludes
external tools/other languages that generate code for later
reuse.   
 
Here we summarize multiple metaprogramming approaches and we 
conclude with the approach of 42 and its balance between gurantees and expressivity

strings
citations:
general workflow: 
  imput->string->eval:
    can fail syntax, type checking, run time
    
   
--------------------
Big General issue:
//NOTE:(first idea, revised after good sleep) TODO: if Size was still undefined, it should not compile
//ADD in normalization to collect as used path to normalize all @P in all comment in eC
//otherwise compilation may introduce compile errors in formerly ok classes
Revised Idea:
comments can contain any @Foo in C: e<<{/* @Foo */} exactly as 
any P is accepted, (even if is mispelled, since is not typed yet)
however, if @Foo (Or a part of a method type) does not exist/not exist yet
introspection will not return a type object for it..
now, what
A:Data<<{B f}
B:Data<<{A f}
should generated?
should we assume B to have == while we generate A?
we "can", since A is not typable, on this way we need an operator that do a redirect from a Doc /*@B*/ ?
looks very fishy, and not very 42ish since we would get the error after the generation
of B, too late to do an "if/catch" around Data<<{B f}.
For example Collections do such "if/catch" to see if == is there

currently available fix:
  Refactor.renamePath(\"A.B" to:\"B")<<{
  A:Data<<{B f  B:Data<<{}}
  B:Data<<{A f}
  ..
  //does not work if here there is something using A/B for metaprogramming, as in
  Foo:A<<{}
  }
Thus, mutually recursive Datas can not be used for metaprogramming
in their scope.. is that bad?
If we accept this pattern as not too bad,
do we still need 
Person:Foo<<{ Persons friends}//can not be Data anyway..
Persons:Collections.vector(of:Person)
 

//TODO:(this still stand) in typing, a class is well typed only if all @P exists

42: Attemping a to reconciliate 2 main trends in Metaprogramming

*Metaprogramming need to support (type) circular datatypes.
Those happens everywhere:
A very simple example, in the contex of a pure OO language,
a String should know his Int lenght(),
and a Int should be able to produce a String toS() representation
of itself.

*Metaprogramming in the functional setting is often seen as a way to
generate the behaviour of a function, knowing his type.
In OO setting, or in general when working with complex datatypes,
metaprogramming is very useful as a way to generate/complete/improve
the "shape" of such datatypes (see F# type providers).

On this line we consider a kind of metaprogramming were
C:e
is a class/datatype name and e is a metaprogramming (closed) expression
that, when executed will produce the datatype.
The shape of the generated datatype is decided by the expression behaviour,
not just by its type:
a type system on the line of MetaML would attempt to
type e as Class<Int m(); String foo()>
This approach requires the type of the result to be encoded in
the expression at the type level.
This disallow the very useful pattern
MyData: FromXML("xml data")//could be JSon or any other data format, including a DB
Where either the shape of the data is used to infer its type
or the data contains its schema (as in a database).

Problems tipical of circular initialization of values are lifted
as problems of circular generation of classes:
For example
A:{B toB() int size()}
B:{A toA() int size()}
is normal -relaxing- looking code with circularity of the type level
While
A:if hasMethodSize(B) then {B toB() int size()} else {B toB()} 
B:if hasMethodSize(A) then {A toA() int size()} else {A toA()}
seams broken code, at least as much as
a=b+1
b=a+1

To make a concrete example,
A:IfFieldsEqualsAddEquals({ Num num; B b;}) //two fields num and b
B:IfFieldsEqualsAddEquals({ Num num; A a;})
IfFieldsEqualsAddEquals should add an equals method that
propagate the check to its fields, but only if all the fields
have an equals method.
What should happens here? should we add equals to both A and B
or to none of the two?  


