Metaprogramming in 42:
Declaratively generate imperative
behavior by functional reasoning.

Imperative programming asks you to write down the
detailed computational step your machine should perform.
This allowed/required the programmer to reason about their
programs by keeping in mind a "toy implementation" of their
hardware.
In object oriented this change:
-Subtyping: A dynamically dispatched method invocation
give us no certainty of the detailed computation steps
that are going to be performed, and
allows/require programmers to reason in function of the
abstract contract of the method: that is
the desired properties of the result in function of the arguments.
The programmers are still in control of the detailed behavior,
but such control is delegated to the programmer that
instantiated such object.
-Subclassing: Under this lens, inheritance
represent a similar loss/transfer of control:
The programmer do not know
the full set of methods a class offers:
this depends of the methods offered by the base class,
and if in a future release the heir is enriched with
more methods, such methods will be injected also in
the heir.

This combination allows a limited declarative programming style.
For example, in
class Foo extends Button{}
We declare Foos to be buttons in a way that
is parametric on what Buttons concretely are.
The programmer of Foo just have to specify little bits
of behaviour to personalize the kind of buttons.
The concrete code is then automatically derived
by composing it with the existing code of Button.

With a streach of immagination, you can immagine Button to
follow the double role of both a class and a class generator/decorator:
You can see this as giving some suggestions to Button
on what code to generate when creating the class Foo.

However, this is very limited:
since the behaviour of inheritance
is set in stone, Button is not very active in deciding
about Foo.

However, this point of view let us read many approaches
(traits, mixins, generics, family polymorphis)
as ways to enrich what Button can do to generate the
required Foo from the hints provided by the programmer,
or as a way to enrich the declarative, domain specific language
that the programmer can use to instruct Decorators.

Compile-time metaprogramming aims to give Buttons
a mind of their own, so that they can perform arbitrarly
complicated steps while generating their heirs.

We show here how just using rename/hide and sum
is possible to generate arbitrary behavior
using inductive functional reasoning.


For example,
A: Stringable <>< { .. }

Can generate a toString method inside of the code { .. },
that is going to be the definition
of class A.

With the operators offered by 42, arbitrary behavior can be generated by reasoning in an inductive style:
first we need to generate our base case; for the toString method is going to  be the fields.
A base case is toString for a class with a single field.
Thus, our base cases is going to be all methods handling with any specific field.
Then we provide a "solver", that is a way to merge two base cases into a more general one.
Finally, we "close" the code by doing some adaptations, here we print [] around the string.

-----
MyDecorator:Resource<><{
//parametric over
  class method Cases cases(Library)
  class method Library baseCase(Case c)
  class method Library solver(Library that,Library acc)
  class method Library close(Library that)
//GENERIC INDUCTIVE CODE
  Case:{}
  Cases:Collection.vector(of:Case)
  class method Library <><(Library that) (
    libs=this.baseCases(that)
    acc=this.fold(libs,acc:{})
    Use.Override[this.close(acc)]<><that
    )

  class method Cases baseCases(Library that)
    Libs[with elem in  this.cases(that) (use[ this.baseCase(elem)])]

  class method Library fold(Libs that,Library acc) {
    if that.isEmpty() (return acc)
    newAcc=this.solver(that.left(),acc:acc)
  }



























Stringable:{
  class method
  Library <><(Library that) (
    libs=this.baseCases(that)
    acc=this.fold(libs,acc:{})
    Use.Override[this.close(acc)]<><that
    )
  class method
  Libs baseCases(Library that)(
    fs=Location.Lib(that).fields()
    Libs[with fi in fs.vals() (use[
      Refactor.rename(selector:\"f" into:fi.selector())<><
      Refactor.redirectType(path:\"T" into:fi.returnType().refTo())<><
      this.baseTrait()
      ])]
    )
  class method Library baseTrait() {//in actual 42 can be harder: printing field name, and different field modifiers
    implements Concept.ToS
    T f
    T:{implements Concept.ToS}
    method toS() this.f().toS()
    }
  class method
  Library fold(Libs that,Library acc) {
    if that.isEmpty() (return acc)
    newAcc=Use.Override[that.left();acc]<><{
      implements Concept.ToS
      method toS() this.#1toS()++S", "+this.#2toS()
      }
    return this.fold(that.withoutLeft(),acc:newAcc)
    }
  class method
  Library close(Library that)
    Use.Override[that]<><{
      implements Concept.ToS, Concept.Classable
      method toS() this.class().readableName()++S"["++this.#1toS()++S"]"
      }
  }
---------------
For example Traits offers many different operations,
and a trait composition operation may look like
Foo: Button[restrict Void onPressed()]+{ method Void onPressed() ... }
Where first the method onPressed is made abstract,
so that a new implementation allowing to customized behavior to react
to such event can be provided.

In a functional perspective, we can see all those kinds of operations as endofunctions from
code literals to code literals, and our code of before may look like

Foo: sum ( (restrict "onPressed()") Button) { method Void onPressed() ... }

From this perspective, Button is just a parameter, not an active member of our operation,
just a piece of code that can be composed by operations provided by the
inheritance system.

This paper will focus on this duality:
*Base classes (as Button) as active members in code generation versus
*Base classes as just parameters of a (expressive but) fixed code composition mechanism.







----------------
Alpha rename must be possible to let libraries add features?
consider nominal or a dictionary variation of structural.
company A and B do not talk
what if I use an object for both A and B services
and A add a method name already present in B
It can work without alpha renaming?


-------------------------
.multipy(byMeter)
.divide/dividing(byKg)
if we had a UnitOfMeasure interface,
declaring  Unit: {class method Library(class UnitOfMeasure that, class UnitOfMeasure per)}
will make some stuff easier?
Check if two units are the same to prevent kg/kg and to
generate only one extractor for kg*kg?

u=a*b  dividing bya=b/dividing byb=a   u /- b  u /-- a
u=a/b  multiply byb=a /divide bya=b   u *-b b/<u = u />b


------------


Conventionally, compiled languages have separated phases of
compilation and execution, and they have a single "main"
execution point or task. In most cases the result of such
task is simply discarded or passed to the operative
system that will most likely ignore it.

42 execution model interleave execution and compilation,
and have many tasks. You can see a task as a generalization of a "main" method/expression.
Executing a 42 program with only one task
is similar to compile the source and then directly execute it.
If we have two or more tasks, then we can see the interleaved
compilation: First enough classes are compiled so that the first
task can be executed.
The result of the first task is code (called Library in 42),
that can be compiled and used for the second task.
That is: the result of a task can be part of the program
needed to run the successive tasks.

This model is an extension of the conventional model of
compilation/execution; tasks are run top to bottom,
and every time a task is run all its dependencies are
well typed, so there can not be a type error while running
a task. In this sense, 42 is a sound typed language.

On the flip side, since compilation happens after arbitrary execution,
we can get compilation errors between task executions.
In case a task terminate with an error/exception, such failure
is propagated as a compilation error.
Task execution can perform arbitrary computation, including taking
input from external sources. This means that different executions of the same
42 program can produce different code, or even terminate with different errors.

However, 42 is safer than approaches based on free meta-programming:
Libraries (code literals) are first class values that are manipulated
with certain operations, and 42 guarantees that
if a task produces a non well typed Library,
such type error was originally present in a Library literal
wrote directly inside such task; that is
type errors will not come from other compiled code.

This is a similar experience to what happens already with
a conventional compiler processing a (group of) classes at a time:
a compilation error is produced while processing a class that
has a type error or make wrong assumptions on the shape of already
compiled classes.
 ---------------

Bugs and programming:
idea
  what you wish for, is incoherent.
specification
  failure to specify what you want
implementation
  failure to implement specification,
  but also null pointers/assertions/invariant failures
environment
  not enough memory/stack disk,
  limitations on the file system structure
  network failures

designing sw is the act of recursivly divide your idea in
sub ideas and then sketch out the other phases in your mind
until you discover that you idea is incoherent.


Glossary:
Towel:
a generalization of standard libraries,
there are many towels, you are encouraged to do your own.
Do you love benefits of monkey patching but hate the drawbacks?
Try towels!
Do you love to code alone and have full control of your
development cycle but you need to make real projects
where cooperation is fundamental to be able to finish
in a single life time?
Try towels and library loading!



Trivializing metaprogramming or supporting metaprogramming?
Metaprogramming is hard.
In 42 we want to support
the difficoult task of creating relayable
metaprogramming operations, that consider all the side case,
not supporting a subset of cases and prevent the others by design.

For example: Data/AddEquals
we wish to add equals to a class,
and to do it by calling equals on all the fields.
This design seams intuitive and "good" but there are a ton
of side cases that needs to be supported. Let see how 42
supports those:

-Simple definitions. No recursive types, no subtyping, all good.
All fields must implement equals, otherwhise error.
This is the trivial case, the goal of 42 design is to support
thinking more than about just this case.
Super trivializing would be a system that just do the task and give error
later if not all the <:Equals are satisfied.

-recursive data
A:AddEquals<><{B b}
B:AddEquals<><{A a}

-nestedclasses
A:AddEquals<><{
  B b
  B:AddEquals<><{A a}
  }
##or
A:AddEquals<><{
  B b
  B:{A a}
  }

Let see how the design of the introspection library will help us to not trivialize AddEquals
We will iterate on the field types
i=Refactor.introspect(lib:that)
Location.Types ts=i.fieldTypes()
with t in ts.vals() (//Type is an interface
  with rc=t.referredClass() (
    on Location.Class.Named /*handle trivial case: need <: Equals*/
    on Location.Class.AnonNested /*do we want to retro fit AddEquals?*/
    on Location.Class.AnonTop/*you require yourself to be <:Equals, should be ok, right?*/
    on Location.Class.Unprocessed/*optimistic behaviour? pessimistic one?*/
    )
//??  catch exception Location.Class.Uncompiled u /*optimistic behaviour? pessimistic one?*/
  )
the purpose of 42 is not to make those decisions once and for all,
but to create a framework where those decisions can be made and documented.


meta level soundness

a class is not well typed if assume something false of
another class.
for example trying to sum Bool.
A class is well typed if assume true facts
for all referred classes.
A class is well typed w.r.t. Ps if assume true facts
for all classes Ps.
an expression containing Libraries and class objects
*refers* to all the classes referred by the Libraries
plus all the class objects, transitivelly.

openPs(p,e)={P| e refers_p P, p(P) not LC}
falsePs(p,e)={P| e refers_p P, p(P)= LC, e assume false over LC}

meta safety: openPs and falsePs never grow
-- but, consider the two solutions:
All:Fix<><{
  Person:Data<><{
    Persons friends
    Persons:Data<><{}
    }
  Persons:Collections.vector(of:Person)
  }

Person:Data<><{
  List friends
  $Top:Data(abstract:\)<><{}
  List:Collections.vector(of:$Top)
  }
---
All:Data[\"Person";\"Car"]<><{
  Person:{
    Car.List cars
    $Top:Data<><{}
    List:Collections.vector(of:$Top)
    }
  Car:{
    Person.List owners
    $Top:Data<><{}
    List:Collections.vector(of:$Top)
    }
  }

---
Collections always take a complete, non class-any parameter.
What if all class object are non-any and to give a
possibly broken one you need {/*@P*/}:imm Library?
common sugar may make it {@P}

in that case, the definition of *refer* can be simpler

  //testing alternative 42
  rc=t.referredClass()
  when (clazz=rc.asNamed() doBla(clazz))//capturing/discarding exception void
  //or with lambdas
  res=$(rc, inf:..)$:rc.matcher(result:Library)<><{
   Info inf
   method (named)
   /*using this.inf() and Named:named get result*/
   method (anonTop)
   /*using this.inf() and AnonTop:anonTop get result*/
   /*etcetera*/
   }
   resL=$(list)$:list.sorter()<><{
     method >(a,b) a.foo()>b.foo()
     }
   resL=list.sort(($:\<><{..}$))
   //what if sintactic sugar
   // ($:\<><{(T x)s..}$((x:e)s)== lambda{(T x=e)s ..}
   resL=list.sort(lambda{method >(a,b) a.foo()>b.foo()})
   //compare with
   resL=list.sort(lambda(a,b)->a.foo()>b.foo() )
    )



----------------------
42 verbosity for good
this. is required
explicit types at method boundaries
types for number/strings
types for collections
"closures" requires explicit passing of environment

res={if cond return e1
 return e2}
 versus
 res=cond?e1:e2

imperative commands allowed if they return void,
otherwise required unused local variable dec
unused1=Foo.bar() //now is clear that I choose to trash return value

overloading vs 42 method selectors: verbose, but not always:
Refactor.rename(selector:\"")
compare with
Java Refactor.renameSelector("")
or
Java Refactor.rename(new Selector(""))

----------------------
42 expressive power
is not important to make a language where
is easy to write a correct program if you know exactly what you want
is important to have wrong programs easily failing well
so, when thinking of a feature
-how can be used to acheive my goal :-(
-how can be misused :-|
-how can be used to guard my code against bugs :-)

good 42 libraries/towels should make you think of what can
go wrong first and upfront, even before completly fleshing out
the desired behaviour

on freedom is slavery:
every language feature that you can use is a feature you need
to guard against, since others can use it too.

many languages have many different kinds of features
In 42 you sort of have 2 main attack mechanism:
interface implementation: a very sharp knife
metaprogramming: an atomic bomb

and many protection mechanisms:
Types and modifiers, exceptions, sandboxing (soon)

---
Immutable list subtypes?
ListToS>= ListPerson ?
since immutable, can I write a list interface and specializations?
how it works with the iterators?
----------------------

(Integrated) Metaprogramming and 42

Integrated metaprogramming is when you can generate code
and compile it/run it without manually import
the generated code in a new program, this include both
compile time and run time metaprogramming, but excludes
external tools/other languages that generate code for later
reuse.

Here we summarize multiple metaprogramming approaches and we
conclude with the approach of 42 and its balance between gurantees and expressivity

strings
citations:
general workflow:
  imput->string->eval:
    can fail syntax, type checking, run time


--------------------
Big General issue:
//NOTE:(first idea, revised after good sleep) TODO: if Size was still undefined, it should not compile
//ADD in normalization to collect as used path to normalize all @P in all comment in eC
//otherwise compilation may introduce compile errors in formerly ok classes
Revised Idea:
comments can contain any @Foo in C: e<<{/* @Foo */} exactly as
any P is accepted, (even if is mispelled, since is not typed yet)
however, if @Foo (Or a part of a method type) does not exist/not exist yet
introspection will not return a type object for it..
now, what
A:Data<<{B f}
B:Data<<{A f}
should generated?
should we assume B to have == while we generate A?
we "can", since A is not typable, on this way we need an operator that do a redirect from a Doc /*@B*/ ?
looks very fishy, and not very 42ish since we would get the error after the generation
of B, too late to do an "if/catch" around Data<<{B f}.
For example Collections do such "if/catch" to see if == is there

currently available fix:
  Refactor.renamePath(\"A.B" to:\"B")<<{
  A:Data<<{B f  B:Data<<{}}
  B:Data<<{A f}
  ..
  //does not work if here there is something using A/B for metaprogramming, as in
  Foo:A<<{}
  }
Thus, mutually recursive Datas can not be used for metaprogramming
in their scope.. is that bad?
If we accept this pattern as not too bad,
do we still need
Person:Foo<<{ Persons friends}//can not be Data anyway..
Persons:Collections.vector(of:Person)


//TODO:(this still stand) in typing, a class is well typed only if all @P exists

42: Attemping a to reconciliate 2 main trends in Metaprogramming

*Metaprogramming need to support (type) circular datatypes.
Those happens everywhere:
A very simple example, in the contex of a pure OO language,
a String should know his Int lenght(),
and a Int should be able to produce a String toS() representation
of itself.

*Metaprogramming in the functional setting is often seen as a way to
generate the behaviour of a function, knowing his type.
In OO setting, or in general when working with complex datatypes,
metaprogramming is very useful as a way to generate/complete/improve
the "shape" of such datatypes (see F# type providers).

On this line we consider a kind of metaprogramming were
C:e
is a class/datatype name and e is a metaprogramming (closed) expression
that, when executed will produce the datatype.
The shape of the generated datatype is decided by the expression behaviour,
not just by its type:
a type system on the line of MetaML would attempt to
type e as Class<Int m(); String foo()>
This approach requires the type of the result to be encoded in
the expression at the type level.
This disallow the very useful pattern
MyData: FromXML("xml data")//could be JSon or any other data format, including a DB
Where either the shape of the data is used to infer its type
or the data contains its schema (as in a database).

Problems tipical of circular initialization of values are lifted
as problems of circular generation of classes:
For example
A:{B toB() int size()}
B:{A toA() int size()}
is normal -relaxing- looking code with circularity of the type level
While
A:if hasMethodSize(B) then {B toB() int size()} else {B toB()}
B:if hasMethodSize(A) then {A toA() int size()} else {A toA()}
seams broken code, at least as much as
a=b+1
b=a+1

To make a concrete example,
A:IfFieldsEqualsAddEquals({ Num num; B b;}) //two fields num and b
B:IfFieldsEqualsAddEquals({ Num num; A a;})
IfFieldsEqualsAddEquals should add an equals method that
propagate the check to its fields, but only if all the fields
have an equals method.
What should happens here? should we add equals to both A and B
or to none of the two?


